from __future__ import annotations

import asyncio
import base64
import datetime as dt
import email
from email import policy
from email.message import EmailMessage
from email.utils import getaddresses, parsedate_to_datetime
import imaplib
import logging
import poplib
import re
import shutil
import uuid
from pathlib import Path
from typing import Any, Iterable, Optional

from markdownify import markdownify
from azure.core.exceptions import ClientAuthenticationError, HttpResponseError

from core.config import settings
from core.context import get_indexer
from services.indexer import Indexer
from .models import (
    EmailAccount,
    EmailAccountCreate,
    EmailAccountSummary,
    EmailMessageRecord,
    EmailMessageSummary,
    EmailMessageContent,
    EmailSyncRequest,
    EmailSyncResult,
)
from core.models import FolderRecord
from services.storage import IndexStorage
from .storage import EmailMixin
from .outlook import (
    OUTLOOK_DEFAULT_CLIENT_ID,
    OUTLOOK_DEFAULT_TENANT_ID,
    OutlookService,
    OutlookAuthError,
    OutlookServiceError,
)

# Re-export for router
__all__ = [
    "EmailService",
    "EmailServiceError",
    "EmailSyncError",
    "EmailAuthError",
    "EmailAccountNotFound",
]

logger = logging.getLogger(__name__)

# Azure Identity's device-code flow legitimately receives 400 responses while waiting
# (e.g., "authorization_pending"). Keep the low-level HTTP logs quieter.
logging.getLogger("azure.core.pipeline.policies.http_logging_policy").setLevel(logging.WARNING)


# Use MSAL-friendly delegated scopes (do not include reserved values like offline_access).
# These must match what the Graph SDK/kiota auth provider requests, otherwise the token cache
# won't be hit and the app will keep prompting.
GRAPH_SCOPES: tuple[str, ...] = (
    "User.Read",
    "Mail.Read",
)


class EmailServiceError(Exception):
    """Base error for email service issues."""


class EmailSyncError(EmailServiceError):
    """Raised when a sync operation fails."""


class EmailAuthError(EmailSyncError):
    """Raised when syncing requires the user to re-authenticate."""


class EmailAccountNotFound(EmailServiceError):
    """Raised when an email account is missing."""


class EmailService(EmailMixin):
    MAX_SYNC_BATCH = 100

    def __init__(self, indexer: Indexer, plugin_id: str = "") -> None:
        # Initialize storage via inherited StorageBase
        super().__init__(plugin_id, db_path=settings.db_path)
        
        self.indexer = indexer
        self._root = settings.paths.runtime_root / "mail"
        self._root.mkdir(parents=True, exist_ok=True)
        self._outlook_service = OutlookService()

    async def start_outlook_auth(self, client_id: str, tenant_id: str) -> str:
        client_id = (client_id or "").strip() or OUTLOOK_DEFAULT_CLIENT_ID
        tenant_id = (tenant_id or "").strip() or OUTLOOK_DEFAULT_TENANT_ID
        return await self._outlook_service.start_auth(client_id, tenant_id)

    async def get_outlook_auth_status(self, flow_id: str) -> dict:
        try:
            return await self._outlook_service.get_auth_status(flow_id)
        except OutlookServiceError as e:
            return {'status': 'error', 'message': str(e)}

    async def complete_outlook_setup(self, flow_id: str, label: str) -> EmailAccountSummary:
        try:
            details = await self._outlook_service.complete_auth(flow_id)
        except OutlookServiceError as e:
            raise EmailServiceError(str(e)) from e

        now = dt.datetime.now(dt.timezone.utc)
        account = EmailAccount(
            id=uuid.uuid4().hex,
            label=label,
            protocol="outlook",
            host="graph.microsoft.com",
            port=443,
            username=details["username"] or "outlook_user",
            secret="",
            use_ssl=True,
            folder="INBOX",
            enabled=True,
            created_at=now,
            updated_at=now,
            client_id=details["client_id"],
            tenant_id=details["tenant_id"]
        )

        self.upsert_email_account(account)
        folder_path = self._ensure_account_folder(account)
        return self._to_summary(account, folder_path)

    def list_accounts(self) -> list[EmailAccountSummary]:
        summaries: list[EmailAccountSummary] = []
        accounts = self.list_email_accounts()
        for account in accounts:
            removed = self.prune_missing_email_messages(account.id)
            if removed:
                logger.info("Pruned %d orphaned email message records for %s", removed, account.label)
            folder_path = self._ensure_account_folder(account)
            summaries.append(self._to_summary(account, folder_path))
        return summaries

    def add_account(self, payload: EmailAccountCreate) -> EmailAccountSummary:
        payload_label = payload.label.strip()
        if not payload_label:
            raise EmailServiceError("Account label is required.")

        now = dt.datetime.now(dt.timezone.utc)
        account = EmailAccount(
            id=uuid.uuid4().hex,
            label=payload_label,
            protocol=payload.protocol,
            host=payload.host.strip(),
            port=self._resolve_port(payload.protocol, payload.port, payload.use_ssl),
            username=payload.username.strip(),
            secret=self._encode_secret(payload.password),
            use_ssl=payload.use_ssl,
            folder=payload.folder.strip() if payload.protocol == "imap" and payload.folder else None,
            enabled=True,
            created_at=now,
            updated_at=now,
            last_synced_at=None,
            last_sync_status=None,
        )

        for existing in self.list_email_accounts():
            if existing.username == account.username and existing.host == account.host:
                raise EmailServiceError("An account with the same host and username already exists.")

        self.upsert_email_account(account)
        folder_path = self._ensure_account_folder(account)
        return self._to_summary(account, folder_path)

    def remove_account(self, account_id: str) -> None:
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        folder_path = self._account_spool_path(account.id)
        folder_id = self._folder_id(account)

        # Remove vectors first
        try:
            self.indexer.vector_store.delete_by_filter(folder_id=folder_id)
        except Exception as exc:
            logger.warning("Failed to remove vectors for account %s: %s", account_id, exc)

        # Remove files from storage (files table)
        # This is important because files table has a foreign key to folders table
        # If we don't delete files first, we might violate FK constraints or leave orphaned records
        # if the FK isn't set to CASCADE (it is ON DELETE CASCADE in schema, but good to be explicit or rely on it)
        # The schema says: folder_id TEXT NOT NULL REFERENCES folders(id) ON DELETE CASCADE
        # So deleting the folder should cascade to files.

        self.delete_email_account(account_id)

        # Also remove the folder record from storage if it exists
        # This triggers the ON DELETE CASCADE for files and chunks
        if self.get_folder(folder_id):
            self.remove_folder(folder_id)

        if folder_path.exists():
            shutil.rmtree(folder_path, ignore_errors=True)

    async def sync_account(self, account_id: str, request: EmailSyncRequest) -> EmailSyncResult:
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")

        folder_path = self._ensure_account_folder(account)

        if account.protocol == "outlook":
            return await self._sync_outlook(account, request, folder_path)

        try:
            batch_limit = self._sanitize_limit(request.limit)
            result = await asyncio.to_thread(self._sync_account_blocking, account, batch_limit, folder_path)
        except EmailSyncError as exc:
            self.update_email_account_sync(
                account.id, last_synced_at=dt.datetime.now(dt.timezone.utc), status=f"error: {exc}")
            raise
        except Exception as exc:  # noqa: BLE001
            logger.exception("Unexpected email sync failure for %s", account.id)
            self.update_email_account_sync(
                account.id, last_synced_at=dt.datetime.now(dt.timezone.utc), status=f"error: {exc}")
            raise EmailSyncError("Unexpected failure while syncing account.") from exc

        if result.new_messages > 0:
            await self.indexer.refresh(folders=[result.folder_id])
            result.indexed = result.new_messages
        else:
            result.indexed = 0

        self.update_email_account_sync(account.id, last_synced_at=result.last_synced_at, status=result.status)
        return result

    async def _sync_outlook(self, account: EmailAccount, request: EmailSyncRequest, folder_path: Path) -> EmailSyncResult:
        try:
            if not (account.client_id or "").strip():
                account.client_id = OUTLOOK_DEFAULT_CLIENT_ID
                self.upsert_email_account(account)
            if not (account.tenant_id or "").strip():
                account.tenant_id = OUTLOOK_DEFAULT_TENANT_ID
                self.upsert_email_account(account)

            logger.info(
                "Syncing Outlook account %s client_id=%s tenant_id=%s",
                account.id,
                account.client_id,
                account.tenant_id,
            )

            limit = self._sanitize_limit(request.limit)

            # Delegate to clean service
            try:
                # Pass username if available to help select the right account from cache
                messages = await self._outlook_service.fetch_messages(
                    client_id=account.client_id,
                    tenant_id=account.tenant_id,
                    limit=limit,
                    username=account.username if account.username and "@" in account.username else None
                )
            except OutlookAuthError as e:
                raise EmailAuthError(str(e)) from e
            except OutlookServiceError as e:
                raise EmailSyncError(str(e)) from e

            existing_ids = set(self.list_email_message_ids(account.id))
            new_records = []

            for msg in messages:
                if msg.id in existing_ids:
                    continue

                # Extract basic fields
                subject = msg.subject or "(No Subject)"
                sender = "Unknown"
                if msg.from_ and msg.from_.email_address:
                    sender = f"{msg.from_.email_address.name or ''} <{msg.from_.email_address.address or ''}>".strip()

                date_val = msg.received_date_time

                recipients: list[str] = []
                if msg.to_recipients:
                    recipients.extend(
                        [r.email_address.address for r in msg.to_recipients if r.email_address]
                    )
                if msg.cc_recipients:
                    recipients.extend(
                        [r.email_address.address for r in msg.cc_recipients if r.email_address]
                    )

                # Process body content
                body_content = ""
                if msg.body and msg.body.content:
                    body_content = self._render_body_markdown(
                        msg.body.content,
                        getattr(msg.body, "content_type", None),
                    )
                elif msg.body_preview:
                    body_content = msg.body_preview

                body_content = body_content.strip() or "_No body content available._"

                # Save to file using the same markdown writer as IMAP
                ts = int(date_val.timestamp()) if date_val else int(dt.datetime.now().timestamp())
                safe_id = "".join(c for c in msg.id if c.isalnum())
                file_name = f"{ts}_{safe_id}.md"
                file_path = folder_path / file_name
                self._write_markdown(file_path, subject, sender, recipients, date_val, body_content)
                file_size = file_path.stat().st_size

                record = EmailMessageRecord(
                    id=uuid.uuid4().hex,
                    account_id=account.id,
                    external_id=msg.id,
                    subject=subject,
                    sender=sender,
                    recipients=recipients,
                    sent_at=date_val or dt.datetime.now(dt.timezone.utc),
                    stored_path=file_path,
                    size=file_size,
                    created_at=dt.datetime.now(dt.timezone.utc),
                )
                new_records.append(record)

            new_count = len(new_records)
            for record in new_records:
                self.record_email_message(record)

            if new_count > 0:
                await self.indexer.refresh(folders=[self._folder_id(account)])

            total_messages = self.count_email_messages(account.id)
            last_synced = dt.datetime.now(dt.timezone.utc)
            message = "No new messages." if new_count == 0 else f"Fetched {new_count} message{'s' if new_count != 1 else ''}."

            self.update_email_account_sync(account.id, last_synced_at=last_synced, status="ok")

            return EmailSyncResult(
                account_id=account.id,
                folder_id=self._folder_id(account),
                folder_path=folder_path,
                new_messages=new_count,
                total_messages=total_messages,
                indexed=new_count,
                last_synced_at=last_synced,
                status="ok",
                message=message,
            )

        except EmailSyncError as exc:
            self.update_email_account_sync(
                account.id,
                last_synced_at=dt.datetime.now(dt.timezone.utc),
                status=f"error: {exc}",
            )
            raise
        except (ClientAuthenticationError, HttpResponseError) as exc:
            logger.exception("Outlook sync auth failed")
            self.update_email_account_sync(
                account.id,
                last_synced_at=dt.datetime.now(dt.timezone.utc),
                status=f"error: {exc}",
            )
            raise EmailAuthError(str(exc)) from exc
        except Exception as exc:
            logger.exception("Outlook sync failed")
            self.update_email_account_sync(
                account.id,
                last_synced_at=dt.datetime.now(dt.timezone.utc),
                status=f"error: {exc}",
            )
            raise EmailSyncError(f"Outlook sync failed: {exc}") from exc

    def list_messages(self, account_id: str, limit: int) -> list[EmailMessageSummary]:
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        records = self.list_email_messages(account_id, limit)
        summaries: list[EmailMessageSummary] = []
        for record in records:
            summary = self._record_to_summary(record)
            if summary:
                summaries.append(summary)
        return summaries

    def get_message(self, message_id: str) -> EmailMessageContent:
        record = self.get_email_message(message_id)
        if not record:
            raise EmailServiceError("Email message not found.")
        markdown = self._read_markdown(record.stored_path)
        summary = self._record_to_summary(record)
        if not summary:
            raise EmailServiceError("Email file missing from disk.")
        return EmailMessageContent(**summary.model_dump(), markdown=markdown)

    def _sync_account_blocking(self, account: EmailAccount, limit: int, folder_path: Path) -> EmailSyncResult:
        secret = self._decode_secret(account.secret)
        existing_ids = set(self.list_email_message_ids(account.id))
        if account.protocol == "imap":
            new_records = self._sync_imap(account, secret, folder_path, existing_ids, limit)
        elif account.protocol == "pop3":
            new_records = self._sync_pop3(account, secret, folder_path, existing_ids, limit)
        else:
            raise EmailSyncError(f"Unsupported protocol: {account.protocol}")

        new_count = len(new_records)
        for record in new_records:
            self.record_email_message(record)

        removed = self.prune_missing_email_messages(account.id)
        if removed:
            logger.info("Pruned %d orphaned email message records for %s", removed, account.label)
        total_messages = self.count_email_messages(account.id)
        last_synced = dt.datetime.now(dt.timezone.utc)
        message = "No new messages." if new_count == 0 else f"Fetched {new_count} message{'s' if new_count != 1 else ''}."

        return EmailSyncResult(
            account_id=account.id,
            folder_id=self._folder_id(account),
            folder_path=folder_path,
            new_messages=new_count,
            total_messages=total_messages,
            indexed=0,
            last_synced_at=last_synced,
            status="ok",
            message=message,
        )

    def _sync_imap(
        self,
        account: EmailAccount,
        password: str,
        spool_path: Path,
        existing_ids: set[str],
        limit: int,
    ) -> list[EmailMessageRecord]:
        client: imaplib.IMAP4 | imaplib.IMAP4_SSL
        if account.use_ssl:
            client = imaplib.IMAP4_SSL(account.host, account.port)
        else:
            client = imaplib.IMAP4(account.host, account.port)

        try:
            client.login(account.username, password)
            mailbox = account.folder or "INBOX"
            status, _ = client.select(mailbox, readonly=True)
            if status != "OK":
                raise EmailSyncError(f"Unable to select mailbox '{mailbox}'.")

            status, data = client.uid("search", None, "ALL")
            if status != "OK" or not data:
                return []
            raw_ids = data[0]
            if not raw_ids:
                return []
            uid_values = [uid for uid in raw_ids.split() if uid]
            uid_values = uid_values[-limit:]

            new_records: list[EmailMessageRecord] = []
            for uid in uid_values:
                status, fetched = client.uid("fetch", uid, "(RFC822)")
                if status != "OK" or not fetched:
                    continue
                message_bytes = fetched[0][1]
                if not message_bytes:
                    continue
                record = self._build_message_record(
                    account,
                    message_bytes,
                    existing_ids,
                    spool_path,
                    external_identifier=uid.decode("ascii", errors="ignore"),
                )
                if record:
                    new_records.append(record)
                    existing_ids.add(record.external_id)
            return new_records
        except EmailSyncError:
            raise
        except Exception as exc:  # noqa: BLE001
            raise EmailSyncError(str(exc)) from exc
        finally:
            try:
                client.logout()
            except Exception:  # noqa: BLE001
                pass

    def _sync_pop3(
        self,
        account: EmailAccount,
        password: str,
        spool_path: Path,
        existing_ids: set[str],
        limit: int,
    ) -> list[EmailMessageRecord]:
        server: poplib.POP3 | poplib.POP3_SSL
        if account.use_ssl:
            server = poplib.POP3_SSL(account.host, account.port, timeout=30)
        else:
            server = poplib.POP3(account.host, account.port, timeout=30)

        try:
            server.user(account.username)
            server.pass_(password)
            response, listings, _ = server.uidl()
            if not listings or b"+OK" not in response:
                return []
            entries = [entry.decode("utf-8", errors="ignore") for entry in listings]
            indexed_entries = []
            for line in entries:
                parts = line.split()
                if len(parts) >= 2:
                    indexed_entries.append((int(parts[0]), parts[1]))
            indexed_entries = indexed_entries[-limit:]

            new_records: list[EmailMessageRecord] = []
            for index, external_id in indexed_entries:
                if external_id in existing_ids:
                    continue
                resp, lines, _ = server.retr(index)
                if b"+OK" not in resp or not lines:
                    continue
                message_bytes = b"\r\n".join(lines) + b"\r\n"
                record = self._build_message_record(
                    account,
                    message_bytes,
                    existing_ids,
                    spool_path,
                    external_identifier=external_id,
                )
                if record:
                    new_records.append(record)
                    existing_ids.add(record.external_id)
            return new_records
        except EmailSyncError:
            raise
        except Exception as exc:  # noqa: BLE001
            raise EmailSyncError(str(exc)) from exc
        finally:
            try:
                server.quit()
            except Exception:  # noqa: BLE001
                pass

    def _build_message_record(
        self,
        account: EmailAccount,
        message_bytes: bytes,
        existing_ids: set[str],
        spool_path: Path,
        *,
        external_identifier: str,
    ) -> Optional[EmailMessageRecord]:
        message = email.message_from_bytes(message_bytes, policy=policy.default)
        external_id = message.get("Message-ID") or external_identifier
        if external_id in existing_ids:
            return None

        body_text = self._extract_text(message)
        sent_at = self._parse_date(message.get("Date"))
        subject = message.get("Subject")
        sender = message.get("From")
        recipients = self._collect_recipients(message)

        timestamp = (sent_at or dt.datetime.now(dt.timezone.utc)).strftime("%Y%m%d-%H%M%S")
        slug = self._slugify(subject or "message")
        filename = f"{timestamp}-{slug}-{uuid.uuid4().hex[:8]}.md"
        target_path = spool_path / filename
        self._write_markdown(target_path, subject, sender, recipients, sent_at, body_text)

        return EmailMessageRecord(
            id=uuid.uuid4().hex,
            account_id=account.id,
            external_id=external_id,
            subject=subject,
            sender=sender,
            recipients=recipients,
            sent_at=sent_at,
            stored_path=target_path,
            size=len(message_bytes),
            created_at=dt.datetime.now(dt.timezone.utc),
        )

    def _ensure_account_folder(self, account: EmailAccount) -> Path:
        folder_path = self._account_spool_path(account.id)
        folder_path.mkdir(parents=True, exist_ok=True)

        existing = self.get_folder(self._folder_id(account))
        now = dt.datetime.now(dt.timezone.utc)
        if existing:
            record = FolderRecord(
                id=existing.id,
                path=folder_path,
                label=existing.label,
                created_at=existing.created_at,
                updated_at=now,
                last_indexed_at=existing.last_indexed_at,
                enabled=True,
            )
        else:
            record = FolderRecord(
                id=self._folder_id(account),
                path=folder_path,
                label=f"Email Â· {account.label}",
                created_at=now,
                updated_at=now,
                last_indexed_at=None,
                enabled=True,
            )
        self.upsert_folder(record)
        return folder_path

    def _to_summary(self, account: EmailAccount, folder_path: Path) -> EmailAccountSummary:
        window = dt.datetime.now(dt.timezone.utc) - dt.timedelta(hours=24)
        total_messages = self.count_email_messages(account.id)
        recent_new = self.count_email_messages_since(account.id, window)
        return EmailAccountSummary(
            id=account.id,
            label=account.label,
            protocol=account.protocol,
            host=account.host,
            port=account.port,
            username=account.username,
            use_ssl=account.use_ssl,
            folder=account.folder,
            enabled=account.enabled,
            created_at=account.created_at,
            updated_at=account.updated_at,
            last_synced_at=account.last_synced_at,
            last_sync_status=account.last_sync_status,
            total_messages=total_messages,
            recent_new_messages=recent_new,
            folder_id=self._folder_id(account),
            folder_path=folder_path,
        )

    def _account_spool_path(self, account_id: str) -> Path:
        return self._root / account_id

    @staticmethod
    def _resolve_port(protocol: str, port: int, use_ssl: bool) -> int:
        if port:
            return port
        if protocol == "imap":
            return 993 if use_ssl else 143
        if protocol == "pop3":
            return 995 if use_ssl else 110
        return port

    @staticmethod
    def _encode_secret(password: str) -> str:
        return base64.b64encode(password.encode("utf-8")).decode("ascii")

    @staticmethod
    def _decode_secret(secret: str) -> str:
        try:
            return base64.b64decode(secret.encode("ascii")).decode("utf-8")
        except Exception as exc:  # noqa: BLE001
            raise EmailServiceError("Stored credentials are corrupted.") from exc

    @staticmethod
    def _collect_recipients(message: EmailMessage) -> list[str]:
        fields = []
        for header in ("To", "Cc", "Bcc"):
            value = message.get(header)
            if value:
                fields.append(value)
        if not fields:
            return []
        addresses = getaddresses(fields)
        return [addr for _, addr in addresses if addr]

    @staticmethod
    def _parse_date(value: Optional[str]) -> Optional[dt.datetime]:
        if not value:
            return None
        try:
            parsed = parsedate_to_datetime(value)
            if parsed and parsed.tzinfo:
                return parsed.astimezone(dt.timezone.utc).replace(tzinfo=None)
            return parsed
        except Exception:  # noqa: BLE001
            return None

    @staticmethod
    def _extract_text(message: EmailMessage) -> str:
        if message.is_multipart():
            for part in message.walk():
                if part.get_content_maintype() == "multipart":
                    continue
                content_type = part.get_content_type()
                if content_type == "text/plain":
                    decoded = EmailService._decode_part(part)
                    if decoded:
                        return decoded
            for part in message.walk():
                if part.get_content_type() == "text/html":
                    html_text = EmailService._decode_part(part)
                    if html_text:
                        return EmailService._html_to_text(html_text)
            return ""
        content_type = message.get_content_type()
        payload = EmailService._decode_part(message)
        if content_type == "text/html":
            return EmailService._html_to_text(payload or "")
        return payload or ""

    @staticmethod
    def _decode_part(part: EmailMessage) -> str:
        try:
            payload = part.get_payload(decode=True)
            if payload is None:
                return ""
            charset = part.get_content_charset() or "utf-8"
            try:
                return payload.decode(charset, errors="replace")
            except LookupError:
                return payload.decode("utf-8", errors="replace")
        except Exception:  # noqa: BLE001
            return ""

    @staticmethod
    def _html_to_text(payload: str) -> str:
        text = re.sub(r"<br\s*/?>", "\n", payload, flags=re.IGNORECASE)
        text = re.sub(r"<[^>]+>", " ", text)
        text = re.sub(r"\s+", " ", text)
        return text.strip()

    @staticmethod
    def _render_body_markdown(content: str, content_type: Any | None) -> str:
        if not content:
            return ""
        if EmailService._looks_like_html(content_type, content):
            return markdownify(
                content,
                heading_style="ATX",
                strip=["script", "style"],
            ).strip()
        return content

    @staticmethod
    def _looks_like_html(content_type: Any | None, content: str) -> bool:
        if content_type is not None:
            raw = getattr(content_type, "value", content_type)
            raw_str = str(raw)
            if "html" in raw_str.lower():
                return True
        return bool(re.search(r"<\w+[^>]*>", content))

    @staticmethod
    def _write_markdown(
        path: Path,
        subject: Optional[str],
        sender: Optional[str],
        recipients: Iterable[str],
        sent_at: Optional[dt.datetime],
        body_text: str,
    ) -> None:
        lines = [
            f"# {subject.strip() if subject else 'Untitled message'}",
            "",
            f"- From: {sender or 'Unknown sender'}",
            f"- To: {', '.join(recipients) if recipients else 'Unknown recipients'}",
            f"- Date: {sent_at.isoformat() if sent_at else 'Unknown'}",
            "",
            body_text.strip() or '_No body content available._',
        ]
        path.write_text("\n".join(lines).strip() + "\n", encoding="utf-8")

    @staticmethod
    def _slugify(value: str) -> str:
        cleaned = re.sub(r"[^a-zA-Z0-9]+", "-", value.lower()).strip("-")
        return cleaned or "message"

    def _folder_id(self, account: EmailAccount) -> str:
        return f"email::{account.id}"

    def _sanitize_limit(self, requested: int | None) -> int:
        if requested is None or requested <= 0:
            return self.MAX_SYNC_BATCH
        return max(1, min(requested, self.MAX_SYNC_BATCH))

    def _record_to_summary(self, record: EmailMessageRecord) -> EmailMessageSummary | None:
        if not record.stored_path.exists():
            return None
        preview = self._extract_preview(record.stored_path)
        return EmailMessageSummary(
            id=record.id,
            account_id=record.account_id,
            subject=record.subject,
            sender=record.sender,
            recipients=record.recipients,
            sent_at=record.sent_at,
            stored_path=record.stored_path,
            size=record.size,
            created_at=record.created_at,
            preview=preview,
        )

    @staticmethod
    def _read_markdown(path: Path) -> str:
        try:
            return path.read_text(encoding="utf-8")
        except FileNotFoundError as exc:
            raise EmailServiceError("Email content file missing.") from exc

    @staticmethod
    def _extract_preview(path: Path, lines: int = 6) -> str | None:
        try:
            content = path.read_text(encoding="utf-8")
        except FileNotFoundError:
            return None
        snippet = [line for line in content.splitlines() if line.strip()][:lines]
        return "\n".join(snippet) if snippet else None

    # ==================== Account-Level Memory Integration Methods (v2.5) ====================

    async def build_account_memory(
        self, 
        account_id: str, 
        user_id: str,
    ) -> dict:
        """
        ä¸ºæ•´ä¸ªé‚®ç®±è´¦æˆ·æ‰¹é‡æ„å»º Memoryï¼ˆä¸€é”®æ„å»ºï¼‰
        
        Args:
            account_id: é‚®ç®±è´¦æˆ· ID
            user_id: ç”¨æˆ· ID
            
        Returns:
            æ„å»ºç»“æœ dict
        """
        import json
        from datetime import datetime, timezone
        
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        
        # è·å–è¯¥è´¦æˆ·ä¸‹æ‰€æœ‰é‚®ä»¶
        messages = self.list_email_messages(account_id, limit=1000)
        if not messages:
            return {
                "success": True,
                "message": "No messages to process",
                "account_id": account_id,
                "total_messages": 0,
                "memcells_created": 0,
                "episodes_created": 0,
                "event_logs_created": 0,
            }
        
        try:
            from services.memory.service import get_memory_service
            from services.memory.api_specs.memory_types import RawDataType, MemCell
            from services.memory.api_specs.memory_models import MemoryType
            from services.storage.memory import (
                MemCellRecord as StorageMemCellRecord,
                EpisodeRecord as StorageEpisodeRecord,
                EventLogRecord as StorageEventLogRecord,
            )
            
            memory_service = get_memory_service()
            group_id = f"email_account::{account_id}"
            
            total_memcells = 0
            total_episodes = 0
            total_event_logs = 0
            
            for record in messages:
                import hashlib
                now = datetime.now(timezone.utc).isoformat()
                # ä½¿ç”¨ç¨³å®šçš„ IDï¼ˆåŸºäº chunk_id çš„ hashï¼‰ï¼Œè¿™æ ·ç›¸åŒé‚®ä»¶çš„ upsert ä¼šæ›´æ–°è€Œä¸æ˜¯åˆ›å»ºæ–°è®°å½•
                chunk_id = f"email_account_{account_id}_{record.id}"
                memcell_id = hashlib.sha256(chunk_id.encode()).hexdigest()[:32]
                
                # è¯»å–é‚®ä»¶å†…å®¹
                try:
                    markdown = self._read_markdown(record.stored_path)
                except Exception as e:
                    logger.warning("Failed to read email %s: %s", record.id, e)
                    continue
                
                # æ„å»ºé‚®ä»¶å…ƒæ•°æ®
                email_metadata = {
                    "account_id": account_id,
                    "message_id": record.id,
                    "subject": record.subject,
                    "sender": record.sender,
                    "recipients": record.recipients,
                    "sent_at": record.sent_at.isoformat() if record.sent_at else None,
                    "source": "email_account_build",
                }
                
                original_data_dict = {
                    "content": markdown,
                    "email_subject": record.subject,
                    "email_sender": record.sender,
                    "email_recipients": record.recipients,
                    "email_date": record.sent_at.isoformat() if record.sent_at else "",
                }
                
                # åˆ›å»º MemCell
                memcell = MemCell(
                    event_id=memcell_id,
                    user_id_list=[user_id],
                    original_data=[original_data_dict],
                    timestamp=datetime.now(timezone.utc),
                    summary=f"Email: {record.subject}" if record.subject else "Email message",
                    group_id=group_id,
                    participants=[record.sender] if record.sender else [],
                    type=RawDataType.DOCUMENT,
                )
                
                # æŒä¹…åŒ– MemCellï¼ˆä½¿ç”¨ç¨³å®šçš„ chunk_idï¼‰
                storage_memcell = StorageMemCellRecord(
                    id=memcell_id,
                    user_id=user_id,
                    original_data=json.dumps([original_data_dict]),
                    summary=f"Email: {record.subject}" if record.subject else "Email message",
                    subject=record.subject,
                    file_id=None,
                    chunk_id=chunk_id,
                    chunk_ordinal=0,
                    type="Document",
                    keywords=None,
                    timestamp=now,
                    metadata=email_metadata,
                )
                memory_service.storage.upsert_memcell(storage_memcell)
                total_memcells += 1
                
                # æå–æƒ…èŠ‚è®°å¿†
                try:
                    logger.info("ğŸ“§ [MEMORY] Extracting episode for email: %s", record.subject or record.id)
                    episode = await memory_service.memory_manager.extract_memory(
                        memcell=memcell,
                        memory_type=MemoryType.EPISODIC_MEMORY,
                        user_id=user_id,
                    )
                    
                    if episode:
                        logger.info("ğŸ“§ [MEMORY] Episode extracted successfully for: %s", record.subject or record.id)
                        # ä½¿ç”¨ç¨³å®šçš„ Episode IDï¼ˆåŸºäº memcell_idï¼‰
                        episode_id = hashlib.sha256(f"{memcell_id}_episode".encode()).hexdigest()[:32]
                        storage_episode = StorageEpisodeRecord(
                            id=episode_id,
                            user_id=user_id,
                            summary=getattr(episode, "summary", record.subject or ""),
                            episode=getattr(episode, "episode", ""),
                            subject=getattr(episode, "subject", record.subject),
                            timestamp=now,
                            parent_memcell_id=memcell_id,
                            metadata=email_metadata,
                        )
                        memory_service.storage.upsert_episode(storage_episode)
                        total_episodes += 1
                        
                        # æå–äº‹ä»¶æ—¥å¿—
                        try:
                            logger.info("ğŸ“§ [MEMORY] Extracting event log for episode: %s", episode_id)
                            event_log = await memory_service.memory_manager.extract_memory(
                                memcell=memcell,
                                memory_type=MemoryType.EVENT_LOG,
                                user_id=user_id,
                                episode_memory=episode,
                            )
                            if event_log:
                                facts = getattr(event_log, "atomic_fact", [])
                                if isinstance(facts, str):
                                    facts = [facts]
                                logger.info("ğŸ“§ [MEMORY] EventLog extracted: %d facts", len(facts))
                                for idx_fact, fact in enumerate(facts):
                                    if fact and fact.strip():
                                        # ä½¿ç”¨ç¨³å®šçš„ EventLog IDï¼ˆåŸºäº episode_id + fact ç´¢å¼•ï¼‰
                                        log_id = hashlib.sha256(f"{episode_id}_fact_{idx_fact}".encode()).hexdigest()[:32]
                                        storage_log = StorageEventLogRecord(
                                            id=log_id,
                                            user_id=user_id,
                                            atomic_fact=fact.strip(),
                                            timestamp=now,
                                            parent_episode_id=episode_id,
                                            metadata={"account_id": account_id, "message_id": record.id},
                                        )
                                        memory_service.storage.upsert_event_log(storage_log)
                                        total_event_logs += 1
                            else:
                                logger.warning("ğŸ“§ [MEMORY] EventLog extraction returned None for episode: %s", episode_id)
                        except Exception as e:
                            logger.error("ğŸ“§ [MEMORY] Event log extraction failed for email %s: %s", record.id, e, exc_info=True)
                    else:
                        logger.warning("ğŸ“§ [MEMORY] Episode extraction returned None for: %s", record.subject or record.id)
                            
                except Exception as e:
                    logger.error("ğŸ“§ [MEMORY] Episode extraction failed for email %s: %s", record.id, e, exc_info=True)
            
            logger.info("ğŸ“§ [MEMORY] Account %s memory built: %d memcells, %d episodes, %d event logs", 
                       account_id, total_memcells, total_episodes, total_event_logs)
            
            return {
                "success": True,
                "message": f"Memory built successfully for {total_memcells} emails",
                "account_id": account_id,
                "total_messages": len(messages),
                "memcells_created": total_memcells,
                "episodes_created": total_episodes,
                "event_logs_created": total_event_logs,
            }
            
        except Exception as e:
            logger.error("Failed to build memory for account %s: %s", account_id, e)
            return {
                "success": False,
                "message": f"Failed to build memory: {str(e)}",
                "account_id": account_id,
                "total_messages": 0,
                "memcells_created": 0,
                "episodes_created": 0,
                "event_logs_created": 0,
            }

    async def build_account_memory_stream(self, account_id: str, user_id: str, force: bool = False):
        """
        æµå¼æ„å»º Memoryï¼Œå®æ—¶æŠ¥å‘Šè¿›åº¦
        
        Args:
            account_id: é‚®ç®±è´¦æˆ· ID
            user_id: ç”¨æˆ· ID
            force: æ˜¯å¦å¼ºåˆ¶é‡å»ºæ‰€æœ‰é‚®ä»¶çš„ Memoryï¼ˆå¿½ç•¥å·²æ‰“æ ‡çš„é‚®ä»¶ï¼‰
        
        Yields:
            è¿›åº¦æ›´æ–° dictï¼ŒåŒ…å« type, current, total, email_subject, memory_result ç­‰å­—æ®µ
        """
        import json
        from datetime import datetime, timezone
        
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        
        # è·å–è¯¥è´¦æˆ·ä¸‹æ‰€æœ‰é‚®ä»¶
        messages = self.list_email_messages(account_id, limit=1000)
        total_count = len(messages)
        
        # åˆå§‹è¿›åº¦
        yield {
            "type": "start",
            "account_id": account_id,
            "total": total_count,
            "force": force,
            "message": f"Starting memory build for {total_count} emails..." + (" (force rebuild)" if force else "")
        }
        
        if not messages:
            yield {
                "type": "complete",
                "account_id": account_id,
                "total": 0,
                "memcells_created": 0,
                "episodes_created": 0,
                "event_logs_created": 0,
                "skipped": 0,
                "message": "No messages to process"
            }
            return
        
        try:
            from services.memory.service import get_memory_service
            from services.memory.api_specs.memory_types import RawDataType, MemCell
            from services.memory.api_specs.memory_models import MemoryType
            from services.storage.memory import (
                MemCellRecord as StorageMemCellRecord,
                EpisodeRecord as StorageEpisodeRecord,
                EventLogRecord as StorageEventLogRecord,
            )
            
            memory_service = get_memory_service()
            group_id = f"email_account::{account_id}"
            
            total_memcells = 0
            total_episodes = 0
            total_event_logs = 0
            total_skipped = 0
            
            for idx, record in enumerate(messages):
                now = datetime.now(timezone.utc).isoformat()
                
                # æ„å»º chunk_id æ¥æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
                chunk_id = f"email_account_{account_id}_{record.id}"
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ MemCellï¼ˆé™¤éæ˜¯ force rebuildï¼‰
                if not force:
                    existing_memcells = memory_service.storage.get_memcells_by_chunk_id(chunk_id)
                    if existing_memcells:
                        total_skipped += 1
                        yield {
                            "type": "skipped",
                            "current": idx + 1,
                            "total": total_count,
                            "percentage": round((idx + 1) / total_count * 100, 1),
                            "email_id": record.id,
                            "email_subject": record.subject or "(No Subject)",
                            "email_sender": record.sender or "",
                            "message": f"Skipping already processed email: {record.subject or '(No Subject)'}",
                            "stats": {
                                "memcells": total_memcells,
                                "episodes": total_episodes,
                                "facts": total_event_logs,
                                "skipped": total_skipped,
                            },
                        }
                        continue
                
                # ä½¿ç”¨ç¨³å®šçš„ IDï¼ˆåŸºäº chunk_id çš„ hashï¼‰ï¼Œè¿™æ ·ç›¸åŒé‚®ä»¶çš„ upsert ä¼šæ›´æ–°è€Œä¸æ˜¯åˆ›å»ºæ–°è®°å½•
                import hashlib
                chunk_id = f"email_account_{account_id}_{record.id}"
                memcell_id = hashlib.sha256(chunk_id.encode()).hexdigest()[:32]
                
                # å½“å‰é‚®ä»¶è¿›åº¦
                yield {
                    "type": "processing",
                    "current": idx + 1,
                    "total": total_count,
                    "percentage": round((idx + 1) / total_count * 100, 1),
                    "email_id": record.id,
                    "email_subject": record.subject or "(No Subject)",
                    "email_sender": record.sender or "",
                    "message": f"Processing email {idx + 1}/{total_count}: {record.subject or '(No Subject)'}"
                }
                
                # è¯»å–é‚®ä»¶å†…å®¹
                try:
                    markdown = self._read_markdown(record.stored_path)
                except Exception as e:
                    # è®°å½•å¤±è´¥çŠ¶æ€
                    self.update_email_memory_status(record.id, 'failed', f"Failed to read email: {str(e)}")
                    yield {
                        "type": "email_error",
                        "current": idx + 1,
                        "total": total_count,
                        "email_id": record.id,
                        "email_subject": record.subject or "(No Subject)",
                        "error": f"Failed to read email: {str(e)}"
                    }
                    continue
                
                # æ„å»ºé‚®ä»¶å…ƒæ•°æ®
                email_metadata = {
                    "account_id": account_id,
                    "message_id": record.id,
                    "subject": record.subject,
                    "sender": record.sender,
                    "recipients": record.recipients,
                    "sent_at": record.sent_at.isoformat() if record.sent_at else None,
                    "source": "email_account_build",
                }
                
                original_data_dict = {
                    "content": markdown,
                    "email_subject": record.subject,
                    "email_sender": record.sender,
                    "email_recipients": record.recipients,
                    "email_date": record.sent_at.isoformat() if record.sent_at else "",
                }
                
                # åˆ›å»º MemCell
                memcell = MemCell(
                    event_id=memcell_id,
                    user_id_list=[user_id],
                    original_data=[original_data_dict],
                    timestamp=datetime.now(timezone.utc),
                    summary=f"Email: {record.subject}" if record.subject else "Email message",
                    group_id=group_id,
                    participants=[record.sender] if record.sender else [],
                    type=RawDataType.DOCUMENT,
                )
                
                # æŒä¹…åŒ– MemCellï¼ˆä½¿ç”¨ç¨³å®šçš„ chunk_idï¼‰
                storage_memcell = StorageMemCellRecord(
                    id=memcell_id,
                    user_id=user_id,
                    original_data=json.dumps([original_data_dict]),
                    summary=f"Email: {record.subject}" if record.subject else "Email message",
                    subject=record.subject,
                    file_id=None,
                    chunk_id=chunk_id,
                    chunk_ordinal=0,
                    type="Document",
                    keywords=None,
                    timestamp=now,
                    metadata=email_metadata,
                )
                memory_service.storage.upsert_memcell(storage_memcell)
                total_memcells += 1
                
                # é‚®ä»¶ç»“æœ
                email_result = {
                    "email_id": record.id,
                    "email_subject": record.subject or "(No Subject)",
                    "memcell_created": True,
                    "episode_created": False,
                    "episode_summary": None,
                    "facts_extracted": [],
                }
                
                # æå–æƒ…èŠ‚è®°å¿†
                try:
                    episode = await memory_service.memory_manager.extract_memory(
                        memcell=memcell,
                        memory_type=MemoryType.EPISODIC_MEMORY,
                        user_id=user_id,
                    )
                    
                    if episode:
                        # ä½¿ç”¨ç¨³å®šçš„ Episode IDï¼ˆåŸºäº memcell_idï¼‰
                        episode_id = hashlib.sha256(f"{memcell_id}_episode".encode()).hexdigest()[:32]
                        episode_summary = getattr(episode, "summary", record.subject or "")
                        episode_content = getattr(episode, "episode", "")
                        
                        # å¦‚æœæ˜¯ force rebuildï¼Œå…ˆåˆ é™¤æ—§çš„ event_logsï¼ˆepisode ä¼šè¢« upsert è¦†ç›–ï¼‰
                        if force:
                            try:
                                memory_service.storage.delete_event_logs_by_episode(episode_id)
                            except Exception:
                                pass  # Ignore if delete fails
                        
                        storage_episode = StorageEpisodeRecord(
                            id=episode_id,
                            user_id=user_id,
                            summary=episode_summary,
                            episode=episode_content,
                            subject=getattr(episode, "subject", record.subject),
                            timestamp=now,
                            parent_memcell_id=memcell_id,
                            metadata=email_metadata,
                        )
                        memory_service.storage.upsert_episode(storage_episode)
                        total_episodes += 1
                        email_result["episode_created"] = True
                        email_result["episode_summary"] = episode_summary[:200] if episode_summary else None
                        
                        # æå–äº‹ä»¶æ—¥å¿—
                        try:
                            event_log = await memory_service.memory_manager.extract_memory(
                                memcell=memcell,
                                memory_type=MemoryType.EVENT_LOG,
                                user_id=user_id,
                                episode_memory=episode,
                            )
                            if event_log:
                                facts = getattr(event_log, "atomic_fact", [])
                                if isinstance(facts, str):
                                    facts = [facts]
                                for idx_fact, fact in enumerate(facts):
                                    if fact and fact.strip():
                                        # ä½¿ç”¨ç¨³å®šçš„ EventLog IDï¼ˆåŸºäº episode_id + fact ç´¢å¼•ï¼‰
                                        log_id = hashlib.sha256(f"{episode_id}_fact_{idx_fact}".encode()).hexdigest()[:32]
                                        storage_log = StorageEventLogRecord(
                                            id=log_id,
                                            user_id=user_id,
                                            atomic_fact=fact.strip(),
                                            timestamp=now,
                                            parent_episode_id=episode_id,
                                            metadata={"account_id": account_id, "message_id": record.id},
                                        )
                                        memory_service.storage.upsert_event_log(storage_log)
                                        total_event_logs += 1
                                        email_result["facts_extracted"].append(fact.strip()[:100])
                        except Exception as e:
                            logger.warning("Event log extraction failed for email %s: %s", record.id, e)
                            # EventLog å¤±è´¥ä¸ç®—æ•´ä½“å¤±è´¥ï¼Œåªæ˜¯è­¦å‘Š
                except Exception as e:
                    logger.warning("Episode extraction failed for email %s: %s", record.id, e)
                    # Episode æå–å¤±è´¥ï¼Œè®°å½•ä¸ºå¤±è´¥çŠ¶æ€
                    self.update_email_memory_status(record.id, 'failed', f"Episode extraction failed: {str(e)}")
                    email_result["error"] = str(e)
                
                # å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œæ ‡è®°ä¸ºæˆåŠŸ
                if "error" not in email_result:
                    self.update_email_memory_status(record.id, 'success')
                
                # å•å°é‚®ä»¶å¤„ç†å®Œæˆ
                yield {
                    "type": "email_complete",
                    "current": idx + 1,
                    "total": total_count,
                    "percentage": round((idx + 1) / total_count * 100, 1),
                    "stats": {
                        "memcells": total_memcells,
                        "episodes": total_episodes,
                        "facts": total_event_logs,
                        "skipped": total_skipped,
                    },
                    "email_result": email_result,
                }
            
            # å…¨éƒ¨å®Œæˆ
            skip_msg = f", {total_skipped} skipped" if total_skipped > 0 else ""
            yield {
                "type": "complete",
                "account_id": account_id,
                "total": total_count,
                "memcells_created": total_memcells,
                "episodes_created": total_episodes,
                "event_logs_created": total_event_logs,
                "skipped": total_skipped,
                "message": f"Memory build complete: {total_memcells} memcells, {total_episodes} episodes, {total_event_logs} facts{skip_msg}"
            }
            
        except Exception as e:
            logger.error("Failed to build memory for account %s: %s", account_id, e)
            yield {
                "type": "error",
                "account_id": account_id,
                "message": f"Failed to build memory: {str(e)}"
            }

    async def retry_single_email(self, account_id: str, message_id: str, user_id: str):
        """
        é‡è¯•å•ä¸ªå¤±è´¥çš„é‚®ä»¶æ‰“æ ‡
        
        Yields:
            è¿›åº¦æ›´æ–° dict
        """
        import json
        import hashlib
        from datetime import datetime, timezone
        
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        
        # è·å–é‚®ä»¶è®°å½•
        record = self.get_email_message(message_id)
        if not record:
            yield {
                "type": "error",
                "message": f"Email message not found: {message_id}"
            }
            return
        
        yield {
            "type": "start",
            "message_id": message_id,
            "subject": record.subject or "(No Subject)",
            "message": f"Retrying email: {record.subject or '(No Subject)'}"
        }
        
        try:
            from services.memory.service import get_memory_service
            from services.memory.api_specs.memory_types import RawDataType, MemCell
            from services.memory.api_specs.memory_models import MemoryType
            from services.storage.memory import (
                MemCellRecord as StorageMemCellRecord,
                EpisodeRecord as StorageEpisodeRecord,
                EventLogRecord as StorageEventLogRecord,
            )
            
            memory_service = get_memory_service()
            group_id = f"email_account::{account_id}"
            
            now = datetime.now(timezone.utc).isoformat()
            chunk_id = f"email_account_{account_id}_{record.id}"
            memcell_id = hashlib.sha256(chunk_id.encode()).hexdigest()[:32]
            
            # è¯»å–é‚®ä»¶å†…å®¹
            try:
                markdown = self._read_markdown(record.stored_path)
            except Exception as e:
                self.update_email_memory_status(record.id, 'failed', f"Failed to read email: {str(e)}")
                yield {
                    "type": "error",
                    "message_id": message_id,
                    "error": f"Failed to read email: {str(e)}"
                }
                return
            
            # æ„å»ºé‚®ä»¶å…ƒæ•°æ®
            email_metadata = {
                "account_id": account_id,
                "message_id": record.id,
                "subject": record.subject,
                "sender": record.sender,
                "recipients": record.recipients,
                "sent_at": record.sent_at.isoformat() if record.sent_at else None,
                "source": "email_retry",
            }
            
            original_data_dict = {
                "content": markdown,
                "email_subject": record.subject,
                "email_sender": record.sender,
                "email_recipients": record.recipients,
                "email_date": record.sent_at.isoformat() if record.sent_at else "",
            }
            
            # åˆ›å»º MemCell
            memcell = MemCell(
                event_id=memcell_id,
                user_id_list=[user_id],
                original_data=[original_data_dict],
                timestamp=datetime.now(timezone.utc),
                summary=f"Email: {record.subject}" if record.subject else "Email message",
                group_id=group_id,
                participants=[record.sender] if record.sender else [],
                type=RawDataType.DOCUMENT,
            )
            
            # æŒä¹…åŒ– MemCell
            storage_memcell = StorageMemCellRecord(
                id=memcell_id,
                user_id=user_id,
                original_data=json.dumps([original_data_dict]),
                summary=f"Email: {record.subject}" if record.subject else "Email message",
                subject=record.subject,
                file_id=None,
                chunk_id=chunk_id,
                chunk_ordinal=0,
                type="Document",
                keywords=None,
                timestamp=now,
                metadata=email_metadata,
            )
            memory_service.storage.upsert_memcell(storage_memcell)
            
            yield {
                "type": "progress",
                "message_id": message_id,
                "step": "memcell",
                "message": "MemCell created"
            }
            
            # æå–æƒ…èŠ‚è®°å¿†
            episode_id = hashlib.sha256(f"{memcell_id}_episode".encode()).hexdigest()[:32]
            episode_created = False
            facts_extracted = []
            
            try:
                # å…ˆåˆ é™¤æ—§çš„ event_logs
                try:
                    memory_service.storage.delete_event_logs_by_episode(episode_id)
                except Exception:
                    pass
                
                episode = await memory_service.memory_manager.extract_memory(
                    memcell=memcell,
                    memory_type=MemoryType.EPISODIC_MEMORY,
                    user_id=user_id,
                )
                
                if episode:
                    episode_summary = getattr(episode, "summary", record.subject or "")
                    episode_content = getattr(episode, "episode", "")
                    
                    storage_episode = StorageEpisodeRecord(
                        id=episode_id,
                        user_id=user_id,
                        summary=episode_summary,
                        episode=episode_content,
                        subject=getattr(episode, "subject", record.subject),
                        timestamp=now,
                        parent_memcell_id=memcell_id,
                        metadata=email_metadata,
                    )
                    memory_service.storage.upsert_episode(storage_episode)
                    episode_created = True
                    
                    yield {
                        "type": "progress",
                        "message_id": message_id,
                        "step": "episode",
                        "message": "Episode extracted"
                    }
                    
                    # æå–äº‹ä»¶æ—¥å¿—
                    try:
                        event_log = await memory_service.memory_manager.extract_memory(
                            memcell=memcell,
                            memory_type=MemoryType.EVENT_LOG,
                            user_id=user_id,
                            episode_memory=episode,
                        )
                        if event_log:
                            facts = getattr(event_log, "atomic_fact", [])
                            if isinstance(facts, str):
                                facts = [facts]
                            for idx_fact, fact in enumerate(facts):
                                if fact and fact.strip():
                                    log_id = hashlib.sha256(f"{episode_id}_fact_{idx_fact}".encode()).hexdigest()[:32]
                                    storage_log = StorageEventLogRecord(
                                        id=log_id,
                                        user_id=user_id,
                                        atomic_fact=fact.strip(),
                                        timestamp=now,
                                        parent_episode_id=episode_id,
                                        metadata={"account_id": account_id, "message_id": record.id},
                                    )
                                    memory_service.storage.upsert_event_log(storage_log)
                                    facts_extracted.append(fact.strip()[:100])
                    except Exception as e:
                        logger.warning("Event log extraction failed for email %s: %s", record.id, e)
                        
            except Exception as e:
                logger.warning("Episode extraction failed for email %s: %s", record.id, e)
                self.update_email_memory_status(record.id, 'failed', f"Episode extraction failed: {str(e)}")
                yield {
                    "type": "error",
                    "message_id": message_id,
                    "error": f"Episode extraction failed: {str(e)}"
                }
                return
            
            # æ ‡è®°ä¸ºæˆåŠŸ
            self.update_email_memory_status(record.id, 'success')
            
            yield {
                "type": "complete",
                "message_id": message_id,
                "subject": record.subject or "(No Subject)",
                "memcell_created": True,
                "episode_created": episode_created,
                "facts_count": len(facts_extracted),
                "message": f"Retry successful: {record.subject or '(No Subject)'}"
            }
            
        except Exception as e:
            logger.error("Failed to retry email %s: %s", message_id, e)
            self.update_email_memory_status(record.id, 'failed', str(e))
            yield {
                "type": "error",
                "message_id": message_id,
                "error": str(e)
            }

    async def get_account_memory_status(self, account_id: str, user_id: str) -> dict:
        """è·å–é‚®ç®±è´¦æˆ·çš„ Memory çŠ¶æ€"""
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        
        try:
            from services.memory.service import get_memory_service
            memory_service = get_memory_service()
            
            # æŸ¥æ‰¾ä¸è¯¥è´¦æˆ·ç›¸å…³çš„ MemCells (é€šè¿‡ group_id å‰ç¼€åŒ¹é…)
            group_id = f"email_account::{account_id}"
            memcells = memory_service.storage.get_memcells_by_group_id(group_id)
            
            if not memcells:
                return {
                    "account_id": account_id,
                    "is_built": False,
                    "memcell_count": 0,
                    "episode_count": 0,
                    "event_log_count": 0,
                    "last_built_at": None,
                }
            
            # ç»Ÿè®¡ episodes å’Œ event logs
            episode_count = 0
            event_log_count = 0
            latest_timestamp = None
            
            for memcell in memcells:
                episodes = memory_service.storage.get_episodes_by_memcell(memcell.id)
                episode_count += len(episodes)
                
                for ep in episodes:
                    logs = memory_service.storage.get_event_logs_by_episode(ep.id)
                    event_log_count += len(logs)
                
                # è·Ÿè¸ªæœ€æ–°æ—¶é—´æˆ³
                if memcell.timestamp:
                    if latest_timestamp is None or memcell.timestamp > latest_timestamp:
                        latest_timestamp = memcell.timestamp
            
            return {
                "account_id": account_id,
                "is_built": True,
                "memcell_count": len(memcells),
                "episode_count": episode_count,
                "event_log_count": event_log_count,
                "last_built_at": latest_timestamp,
            }
            
        except Exception as e:
            logger.warning("Failed to get memory status for account %s: %s", account_id, e)
            return {
                "account_id": account_id,
                "is_built": False,
                "memcell_count": 0,
                "episode_count": 0,
                "event_log_count": 0,
                "last_built_at": None,
            }

    async def account_qa(
        self, 
        account_id: str, 
        question: str, 
        user_id: str,
    ) -> dict:
        """
        é‚®ç®±è´¦æˆ·çº§åˆ«é—®ç­”ï¼šåŸºäºè¯¥è´¦æˆ·çš„æ‰€æœ‰é‚®ä»¶è®°å¿†è¿›è¡Œé—®ç­”
        
        Args:
            account_id: é‚®ç®±è´¦æˆ· ID
            question: ç”¨æˆ·é—®é¢˜
            user_id: ç”¨æˆ· ID
            
        Returns:
            QA ç»“æœ dict
        """
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        
        try:
            from core.context import get_llm_client
            from services.memory.service import get_memory_service
            
            llm_client = get_llm_client()
            memory_service = get_memory_service()
            sources = []
            
            # è·å–è¯¥è´¦æˆ·çš„é‚®ä»¶è®°å¿† (é€šè¿‡ group_id è¿‡æ»¤)
            group_id = f"email_account::{account_id}"
            memcells = memory_service.storage.get_memcells_by_group_id(group_id)
            
            # æ„å»ºé‚®ä»¶ä¸Šä¸‹æ–‡
            email_context = f"""## é‚®ç®±ä¿¡æ¯
- é‚®ç®±: {account.label} ({account.username})
- å·²ç´¢å¼•é‚®ä»¶æ•°: {len(memcells)}
"""
            
            # è·å–ç›¸å…³è®°å¿† (åŸºäºé—®é¢˜æ£€ç´¢)
            memory_context = ""
            if memcells:
                # ç®€å•æ–¹æ³•ï¼šéå† memcells æ‰¾åˆ°ç›¸å…³çš„
                # æ›´å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨å‘é‡æ£€ç´¢ï¼Œä½†è¿™é‡Œç®€åŒ–å¤„ç†
                relevant_memories = []
                for memcell in memcells[:20]:  # é™åˆ¶æ•°é‡é¿å…å¤ªé•¿
                    try:
                        import json
                        data = json.loads(memcell.original_data) if isinstance(memcell.original_data, str) else memcell.original_data
                        if isinstance(data, list) and len(data) > 0:
                            content = data[0].get("content", "")[:500]  # æˆªæ–­
                            subject = data[0].get("email_subject", "")
                            sender = data[0].get("email_sender", "")
                            relevant_memories.append({
                                "subject": subject,
                                "sender": sender,
                                "preview": content[:200],
                            })
                            sources.append({
                                "type": "email_memory",
                                "id": memcell.id,
                                "subject": subject,
                                "sender": sender,
                            })
                    except Exception:
                        pass
                
                if relevant_memories:
                    memory_context = "\n\n## é‚®ä»¶è®°å¿†æ‘˜è¦\n"
                    for i, mem in enumerate(relevant_memories[:10], 1):
                        memory_context += f"{i}. **{mem['subject']}** (from: {mem['sender']})\n"
                        memory_context += f"   {mem['preview'][:100]}...\n\n"
            
            # æ„å»º prompt
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½é‚®ä»¶åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·åˆ†æå’Œç†è§£ä»–ä»¬çš„é‚®ç®±å†…å®¹ã€‚
å½“å‰ç”¨æˆ·æ­£åœ¨æŸ¥è¯¢é‚®ç®± "{account.label}" ä¸­çš„é‚®ä»¶ä¿¡æ¯ã€‚
è¯·åŸºäºæä¾›çš„é‚®ä»¶è®°å¿†å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å›ç­”è¦ç®€æ´å‡†ç¡®ï¼Œå¦‚æœä¿¡æ¯ä¸è¶³è¯·æ˜ç¡®è¯´æ˜ã€‚"""
            
            user_prompt = f"""
{email_context}
{memory_context}

## ç”¨æˆ·é—®é¢˜
{question}

è¯·åŸºäºä¸Šè¿°é‚®ä»¶è®°å¿†å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š"""
            
            # è°ƒç”¨ LLM
            answer = await llm_client.chat_complete(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.7,
                max_tokens=1024,
            )
            
            return {
                "answer": answer,
                "sources": sources[:10],  # é™åˆ¶è¿”å›æ•°é‡
                "account_id": account_id,
                "memories_used": len(sources),
            }
            
        except Exception as e:
            logger.error("Account QA failed for %s: %s", account_id, e)
            raise EmailServiceError(f"QA failed: {str(e)}") from e

    async def get_account_memory_details(
        self, 
        account_id: str, 
        user_id: str,
        limit: int = 50,
    ) -> dict:
        """
        è·å–é‚®ç®±è´¦æˆ·çš„ Memory è¯¦æƒ…ï¼šMemCellsã€Episodes å’Œ Facts åˆ—è¡¨
        
        Args:
            account_id: é‚®ç®±è´¦æˆ· ID
            user_id: ç”¨æˆ· ID
            limit: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            åŒ…å« memcellsã€episodesã€facts åˆ—è¡¨çš„ dict
        """
        account = self.get_email_account(account_id)
        if not account:
            raise EmailAccountNotFound("Email account not found.")
        
        try:
            from services.memory.service import get_memory_service
            import json
            
            memory_service = get_memory_service()
            group_id = f"email_account::{account_id}"
            
            # è·å–è¯¥è´¦æˆ·çš„æ‰€æœ‰ MemCells
            memcells = memory_service.storage.get_memcells_by_group_id(group_id)
            
            memcells_list = []
            episodes_list = []
            facts_list = []
            
            for memcell in memcells[:limit]:
                # ä» memcell çš„ original_data ä¸­æå–é‚®ä»¶ä¿¡æ¯
                email_subject = None
                email_sender = None
                email_preview = None
                try:
                    if memcell.original_data:
                        data = json.loads(memcell.original_data) if isinstance(memcell.original_data, str) else memcell.original_data
                        if isinstance(data, list) and len(data) > 0:
                            email_subject = data[0].get("email_subject")
                            email_sender = data[0].get("email_sender")
                            content = data[0].get("content", "")
                            email_preview = content[:200] if content else None
                except Exception:
                    pass
                
                # æ·»åŠ  MemCell
                memcells_list.append({
                    "id": memcell.id,
                    "email_subject": email_subject or memcell.subject or "(No Subject)",
                    "email_sender": email_sender or "",
                    "preview": email_preview or memcell.summary or "",
                    "timestamp": memcell.timestamp,
                })
                
                # è·å– MemCell å…³è”çš„ Episodes
                episodes = memory_service.storage.get_episodes_by_memcell(memcell.id)
                
                for ep in episodes:
                    # æ·»åŠ  Episode
                    episodes_list.append({
                        "id": ep.id,
                        "memcell_id": memcell.id,
                        "email_subject": email_subject or ep.subject,
                        "summary": ep.summary or "",
                        "episode": ep.episode or "",
                        "timestamp": ep.timestamp,
                    })
                    
                    # è·å– Episode å…³è”çš„ EventLogs (Facts)
                    event_logs = memory_service.storage.get_event_logs_by_episode(ep.id)
                    for log in event_logs:
                        if log.atomic_fact:
                            facts_list.append({
                                "id": log.id,
                                "episode_id": ep.id,
                                "email_subject": email_subject or ep.subject,
                                "fact": log.atomic_fact,
                                "timestamp": log.timestamp,
                            })
            
            result = {
                "account_id": account_id,
                "memcells": memcells_list,
                "episodes": episodes_list,
                "facts": facts_list,
                "total_memcells": len(memcells_list),
                "total_episodes": len(episodes_list),
                "total_facts": len(facts_list),
            }
            logger.info(
                "get_account_memory_details: account=%s, memcells=%d, episodes=%d, facts=%d",
                account_id, len(memcells_list), len(episodes_list), len(facts_list)
            )
            return result
            
        except Exception as e:
            logger.warning("Failed to get memory details for account %s: %s", account_id, e)
            return {
                "account_id": account_id,
                "memcells": [],
                "episodes": [],
                "facts": [],
                "total_memcells": 0,
                "total_episodes": 0,
                "total_facts": 0,
            }

# Lazy initialization of service
email_service_global: Optional[EmailService] = None

def get_email_service() -> EmailService:
    global email_service_global

    if email_service_global is None:
        raise RuntimeError("Email service not initialized")
    return email_service_global

def init_plugin_service(indexer: Indexer, plugin_id: str = "") -> EmailService:
    global email_service_global
    
    if email_service_global is None:
        try:
            # EmailService now inherits from StorageBase and initializes its own connection
            email_service_global = EmailService(indexer, plugin_id)
        except Exception as e:
            logger.warning(f"Failed to initialize global email service: {e}")
            
    if email_service_global:
        return email_service_global

    raise RuntimeError("Email service not initialized")

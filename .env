# =============================================================================
# Local Cocoa service Configuration
# =============================================================================
# This file contains default configuration values for the Local Cocoa backend.
# Copy this file to .env.dev, .env.test, or .env.prod and customize as needed.
# The ENVIRONMENT variable (default: dev) determines which env file to load.
# =============================================================================
PYTHONUNBUFFERED=1

# =============================================================================
# Service Endpoints
# =============================================================================
LOCAL_SERVICE_MAIN_HOST=127.0.0.1
LOCAL_SERVICE_MAIN_PORT=8890

LOCAL_SERVICE_LLM_HOST=<LOCAL_SERVICE_MAIN_HOST>
LOCAL_SERVICE_LLM_PORT=8007

LOCAL_SERVICE_EMBEDDING_HOST=<LOCAL_SERVICE_MAIN_HOST>
LOCAL_SERVICE_EMBEDDING_PORT=8005

LOCAL_SERVICE_RERANK_HOST=<LOCAL_SERVICE_MAIN_HOST>
LOCAL_SERVICE_RERANK_PORT=8006

LOCAL_SERVICE_VISION_HOST=<LOCAL_SERVICE_MAIN_HOST>
LOCAL_SERVICE_VISION_PORT=8007

LOCAL_SERVICE_TRANSCRIBE_HOST=<LOCAL_SERVICE_MAIN_HOST>
LOCAL_SERVICE_TRANSCRIBE_PORT=8080

# =============================================================================
# Path Settings
# =============================================================================
# Root directory for local runtime environment (empty = use system default)
LOCAL_RUNTIME_ROOT=runtime

LOCAL_MODEL_ROOT_PATH=<LOCAL_RUNTIME_ROOT>/local-cocoa-models/pretrained

# Root path of all the binary exeution files (local-cocoa-server、llama、whisper)
LOCAL_SERVICE_BIN_ROOT=dist

LOCAL_LLAMA_SERVER_PATH=<LOCAL_SERVICE_BIN_ROOT>/llama-cpp/bin

LOCAL_WHISPER_SERVER_PATH=<LOCAL_SERVICE_BIN_ROOT>/whisper-cpp/bin

# User plugins directory (optional, for downloadable/user-installed plugins)
LOCAL_USER_PLUGINS_ROOT=dist/user-plugins

# =============================================================================
# Model Settings
# =============================================================================

LOCAL_MODEL_EMBEDDING_FILE=Qwen3-Embedding-0.6B-Q4_K_M.gguf

LOCAL_MODEL_RERANK_FILE=bge-reranker-v2-m3-q8_0.gguf

LOCAL_MODEL_VLM_FILE=qwenvl/Qwen3VL-2B-Instruct-Q4_K_M.gguf

LOCAL_MODEL_VLM_MMPROJ_FILE=qwenvl/mmproj-Qwen3VL-2B-Instruct-Q8_0.gguf

LOCAL_MODEL_WHISPER_FILE=ggml-small.bin

LOCAL_MODEL_IDLE_TIMEOUT=300

LOCAL_MODEL_MANAGER_ENABLED=true

# =============================================================================
# RAG Settings
# =============================================================================

# Poll interval in seconds for file system monitoring
LOCAL_RAG_POLL_INTERVAL_SECONDS=90

# Whether to refresh index on startup
LOCAL_RAG_REFRESH_ON_STARTUP=true

# Database filename
LOCAL_RAG_DB_NAME=index.sqlite

# Maximum directory depth to traverse
LOCAL_RAG_MAX_DEPTH=12

# Whether to follow symbolic links
LOCAL_RAG_FOLLOW_SYMLINKS=false

# Whether to reuse existing embeddings
LOCAL_RAG_REUSE_EMBEDDINGS=true

# Embedding batch size (minimum: 1)
LOCAL_RAG_EMBED_BATCH_SIZE=32

# Delay for lightweight text embedding operations in milliseconds
# Default: 0ms (no delay for text embeddings)
LOCAL_RAG_EMBED_BATCH_DELAY_MS=0

# Delay for heavy vision/LLM operations in milliseconds
# Default: 200ms to prevent GPU saturation
LOCAL_RAG_VISION_BATCH_DELAY_MS=200

# Maximum characters to send to embedding model (minimum: 256)
LOCAL_RAG_EMBED_MAX_CHARS=1600

# Snapshot interval in seconds
LOCAL_RAG_SNAPSHOT_INTERVAL_SECONDS=600

# Chunk size for RAG processing
LOCAL_RAG_CHUNK_SIZE=200

# Chunk overlap for RAG processing
LOCAL_RAG_CHUNK_OVERLAP=40

# =============================================================================
# Qdrant Vector Database Settings
# =============================================================================
# Path to Qdrant storage.
LOCAL_QDRANT_DATA_PATH=<LOCAL_RUNTIME_ROOT>/qdrant-data

# Collection name
LOCAL_QDRANT_COLLECTION_NAME=local-coacoa-files

# Embedding dimension
LOCAL_QDRANT_EMBEDDING_DIM=1024

# Distance metric (COSINE/DOT/EUCLID)
LOCAL_QDRANT_METRIC_TYPE=COSINE

# =============================================================================
# LLM Settings
# =============================================================================
# Context window size in tokens (minimum: 2048)
LOCAL_LLM_CONTEXT_TOKENS=32768

# Maximum prompt tokens (minimum: 1024)
LOCAL_LLM_MAX_PROMPT_TOKENS=32768

# Average characters per token (minimum: 1)
LOCAL_LLM_CHARS_PER_TOKEN=8

# =============================================================================
# Vision Settings
# =============================================================================
# Maximum pixels for vision processing
# Default: ~1MP (1280*28*28 ≈ 1,003,520 pixels)
# Low spec mode: ~200k (256*28*28 ≈ 200,000 pixels)
LOCAL_VISION_MAX_PIXELS=1003520

# Maximum pixels for video frame processing
# Default: ~480p (640×480 = 307,200 pixels)
# Lower than images since we process multiple frames
LOCAL_VIDEO_MAX_PIXELS=307200

# =============================================================================
# Search Settings
# =============================================================================
# Maximum number of search results to return
LOCAL_SEARCH_RESULT_LIMIT=15

# Number of context chunks for QA
LOCAL_QA_CONTEXT_LIMIT=5

# Maximum length of text snippets in characters
LOCAL_MAX_SNIPPET_LENGTH=2000

# =============================================================================
# Summary Settings
# =============================================================================
# Maximum output tokens for file summaries (minimum: 32)
LOCAL_SUMMARY_MAX_TOKENS=100

# Maximum input characters for summarization
LOCAL_SUMMARY_INPUT_MAX_CHARS=100000

# =============================================================================
# PDF Settings
# =============================================================================
# Maximum output tokens when VLM processes a PDF page (minimum: 256)
# Default: 2048 to leave room for image tokens and prompts
# Set higher (3072-4096) for complex pages with tables/charts
LOCAL_PDF_PAGE_MAX_TOKENS=2048

# PDF processing mode: "text" (OCR) or "vision" (VLM per-page analysis)
LOCAL_PDF_MODE=vision

# PDF chunking mode:
# - true: one chunk per page (faster indexing, simpler UI)
# - false: allow multiple chunks (better retrieval granularity)
LOCAL_PDF_ONE_CHUNK_PER_PAGE=false

# =============================================================================
# Indexing Mode
# =============================================================================
# Default indexing mode for new files:
# - "fast": Quick text-based indexing, good for most documents
# - "deep": Deep vision-based analysis, better for images, complex PDFs
LOCAL_DEFAULT_INDEXING_MODE=fast

# =============================================================================
# Memory Extraction Settings
# =============================================================================
# Enable memory extraction (episodes, foresights, event logs)
LOCAL_ENABLE_MEMORY_EXTRACTION=true

# User ID for memory extraction
LOCAL_MEMORY_USER_ID=default_user

# Memory extraction stage:
# - "fast": Extract during fast indexing (quicker, text-based)
# - "deep": Extract during deep indexing (slower, richer content after VLM)
# - "none": Disable automatic extraction (manual trigger only)
LOCAL_MEMORY_EXTRACTION_STAGE=none

# Memory chunk size for extraction:
# - 0: Use original indexed chunks (supports resume)
# - >0: Re-chunk with this size (no resume support)
# Recommended: 2000-5000 for efficiency, or 0 for granularity
LOCAL_MEMORY_CHUNK_SIZE=0

# =============================================================================
# Logging
# =============================================================================
LOG_LEVEL=INFO

LOCAL_SERVICE_LOG_TO_FILE=true

# Below all under LOCAL_RUNTIME_ROOT
LOCAL_MAIN_LOG_PATH=<LOCAL_RUNTIME_ROOT>/logs/main.log

LOCAL_EMBED_LOG_PATH=<LOCAL_RUNTIME_ROOT>/logs/embed.log

LOCAL_RERANK_LOG_PATH=<LOCAL_RUNTIME_ROOT>/logs/rerank.log

LOCAL_VLM_LOG_PATH=<LOCAL_RUNTIME_ROOT>/logs/vlm.log

LOCAL_WHISPER_LOG_PATH=<LOCAL_RUNTIME_ROOT>/logs/whisper.log